{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4ba78e",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee7d055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00417d81",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8290dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for loading data from disk\n",
    "def load_mnist_digits():\n",
    "\n",
    "    train_df = pd.read_csv('datasets/mnist-digits.csv')\n",
    "\n",
    "    y = np.array(pd.get_dummies(train_df['label']))\n",
    "\n",
    "    X = train_df.drop(['label'], axis=1)\n",
    "    X = np.array(X)/255.0\n",
    "    X = X - 0.5\n",
    "\n",
    "    X = X.reshape(X.shape[0],28,28)\n",
    "    y = np.expand_dims(y, axis=1)\n",
    "    del train_df\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "765a684b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation function\n",
    "def softmax(z):\n",
    "    exp = np.exp(z)\n",
    "    return exp / np.sum(exp, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec1abded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "def cross_entropy_loss(y, pred, epsilon=1e-15, num_classes=10):\n",
    "    pred = np.clip(pred, epsilon, 1-epsilon)\n",
    "    loss = -np.sum(y * np.log(pred))/num_classes\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e671f963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for calculating model accuracy on given features\n",
    "def calculate_accuracy_score(features, labels, layers):\n",
    "    truths, preds = [], []\n",
    "    for i in range(0, features.shape[0]):\n",
    "        truths.append(np.argmax(labels[i]))\n",
    "        preds.append(np.argmax(predict(layers, features[i])))\n",
    "    \n",
    "    return accuracy_score(truths, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a45d7b",
   "metadata": {},
   "source": [
    "### Dataset: MNIST Digits\n",
    "The MNIST dataset is a collection of 28x28 pixel grayscale images of handwritten digits (0-9), widely used for training and evaluating machine learning models. It consists of 60,000 training samples and 10,000 test samples, making it a popular benchmark for digit recognition tasks.\n",
    "\n",
    "For simplicity, Here we are using only 12000 samples for faster training process.\n",
    "<br>This dataset is collected from [Kaggle - Digit Recognizer Dataset](https://www.kaggle.com/competitions/digit-recognizer/data), full dataset credits goes to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47c0a385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28, 28), (1, 10))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = load_mnist_digits()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[:12000], y[:12000], test_size=2000, random_state=42)\n",
    "X_train[0].shape, y_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e71ca5",
   "metadata": {},
   "source": [
    "### Model: Convolutional Neural Networks (CNNs)\n",
    "Introduced by Yann LeCun in the 1990s, CNNs are designed for processing grid-like data, such as images. They use convolutional layers to automatically and adaptively learn spatial hierarchies of features from input images.\n",
    "\n",
    "The architecture of a Convolutional Neural Network (CNN) includes:\n",
    "\n",
    "1. Convolutional Layers: These layers apply filters to extract spatial features from input data, making them well-suited for image and spatial data analysis.\n",
    "\n",
    "2. Pooling Layers: These layers downsample the features to reduce the computational load and improve translation invariance.\n",
    "\n",
    "3. Fully Connected Layers: These layers process the extracted features to make predictions or classifications.\n",
    "\n",
    "4. Training: CNNs are trained using backpropagation and optimization techniques to learn patterns in data.\n",
    "\n",
    "CNNs are commonly used in computer vision tasks, image recognition, and other spatial data analysis applications due to their ability to capture local patterns efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4218fcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer:\n",
    "    \n",
    "    last_input = np.array([])\n",
    "    pool_out_shape = []\n",
    "    \n",
    "    def __init__(self,nodes_in=0, nodes_out=10):\n",
    "        self.nodes_in, self.nodes_out = nodes_in, nodes_out\n",
    "        self.weights = np.random.randn(self.nodes_out, self.nodes_in)/np.sqrt(self.nodes_out)\n",
    "        self.biases = np.random.randn(1, self.nodes_out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        if len(self.pool_out_shape) <=0: self.pool_out_shape = x.shape\n",
    "        x = x.flatten()\n",
    "        x = x.reshape(x.shape + (1,)).T\n",
    "        self.last_input = x\n",
    "        self.a = softmax(np.dot(x, self.weights.T) + self.biases)\n",
    "        return self.a\n",
    "\n",
    "    def backward(self, y, lr):\n",
    "        error = y - self.a\n",
    "        pool_error = error.dot(self.weights).reshape(self.pool_out_shape)\n",
    "        self.weights += lr * error.T.dot(self.last_input)\n",
    "        self.biases  += lr * error\n",
    "        return pool_error\n",
    "\n",
    "class MaxPoolLayer:\n",
    "\n",
    "    image_shape = [0, 0]\n",
    "    num_filters = 0\n",
    "    \n",
    "    def forward(self, input_image):\n",
    "        \n",
    "        self.last_input = input_image\n",
    "        self.image_shape[0], self.image_shape[1], self.num_filters = input_image.shape\n",
    "        output = np.zeros(((self.image_shape[0]//2), (self.image_shape[1]//2), self.num_filters))\n",
    "        for i in range((self.image_shape[0] // 2)):\n",
    "            for j in range((self.image_shape[1] // 2)):\n",
    "                selected_region = input_image[(i*2):(i*2+2),(j*2):(j*2+2)]\n",
    "                output[i, j] = np.amax(selected_region, axis=(0, 1))\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def backprop(self, error):\n",
    "        \n",
    "        conv_error = np.zeros(self.last_input.shape)\n",
    "        for i in range(self.last_input.shape[0]//2):\n",
    "            for j in range(self.last_input.shape[1]//2):   \n",
    "                selected_region = self.last_input[(i * 2):(i * 2 + 2), (j * 2):(j * 2 + 2)]\n",
    "                h, w, f = selected_region.shape\n",
    "                amax = np.amax(selected_region, axis=(0, 1))\n",
    "        \n",
    "        for i2 in range(h):\n",
    "            for j2 in range(w):\n",
    "                for f2 in range(f):\n",
    "                    # If this pixel was the max value, copy the gradient to it.\n",
    "                    if selected_region[i2, j2, f2] == amax[f2]:\n",
    "                        conv_error[i * 2 + i2, j * 2 + j2, f2] = error[i, j, f2]\n",
    "        \n",
    "        return conv_error\n",
    "\n",
    "class ConvLayer:\n",
    "    \n",
    "    def __init__(self, num_filters, filter_shape = (2,2)):\n",
    "        self.num_filters = num_filters\n",
    "        self.filter_shape = filter_shape\n",
    "        self.filters = np.random.randn(num_filters, filter_shape[0], filter_shape[1]) / (filter_shape[0] * filter_shape[1])\n",
    "    \n",
    "    def forward(self, input_image):\n",
    "        self.last_input = input_image\n",
    "        output = np.zeros((input_image.shape[0] - 2, input_image.shape[1] - 2, self.num_filters))\n",
    "        for i in range(input_image.shape[0] - 2):\n",
    "            for j in range(input_image.shape[1] - 2):\n",
    "                selected_region = input_image[i:(i+self.filter_shape[0]), j:(j+self.filter_shape[1])]\n",
    "                output[i, j] = np.sum(selected_region * self.filters, axis=(1, 2))\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def backprop(self, conv_error, lr):\n",
    "        new_filters_weights = np.zeros(self.filters.shape)\n",
    "        for i in range(self.last_input.shape[0] - 2):\n",
    "            for j in range(self.last_input.shape[1] - 2):\n",
    "                selected_region = self.last_input[i:(i+self.filter_shape[0]), j:(j+self.filter_shape[1])]\n",
    "                for k in range(self.num_filters):\n",
    "                    new_filters_weights[k] += conv_error[i, j, k] * selected_region\n",
    "        \n",
    "        self.filters += lr * new_filters_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b45d567",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b07c3aec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(layers, X_train, y_train, epochs, learning_rate):\n",
    "    \n",
    "    conv_layer, pool_layer, dense_layer = layers\n",
    "    batch_size = X_train.shape[0]\n",
    "    epoch_losses = []\n",
    "    for e in range(epochs):\n",
    "        \n",
    "        batch_loss = []\n",
    "        for i in range(0, batch_size):\n",
    "            \n",
    "            # feedforward\n",
    "            conv_layer_output = conv_layer.forward(X_train[i])\n",
    "            pool_layer_output = pool_layer.forward(conv_layer_output)\n",
    "            dense_layer_output = dense_layer.forward(pool_layer_output)\n",
    "            \n",
    "            loss = cross_entropy_loss(y_train[i], dense_layer_output)\n",
    "            \n",
    "            # backpropagation\n",
    "            pool_error = dense_layer.backward(y_train[i], lr=learning_rate)\n",
    "            conv_error = pool_layer.backprop(pool_error)\n",
    "            conv_layer.backprop(conv_error, lr=learning_rate)\n",
    "            batch_loss.append(loss)\n",
    "\n",
    "        epoch_losses.append(np.sum(batch_loss)/batch_size)\n",
    "        print(\"epoch \",(e+1),\"\\t...\\tloss:\",np.sum(epoch_losses)/(e+1))\n",
    "\n",
    "def predict(layers, x):\n",
    "    pred = x\n",
    "    for layer in layers:\n",
    "        pred = layer.forward(pred)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea97619c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1 \t...\tloss: 0.15261140851375674\n",
      "epoch  2 \t...\tloss: 0.1123394032620471\n",
      "epoch  3 \t...\tloss: 0.09371198967027322\n"
     ]
    }
   ],
   "source": [
    "conv_layer = ConvLayer(20, (3,3))\n",
    "pool_layer = MaxPoolLayer()\n",
    "dense_layer = DenseLayer(3380, 10)\n",
    "\n",
    "layers = [conv_layer, pool_layer, dense_layer]\n",
    "\n",
    "epochs = 3\n",
    "learning_rate = 0.001\n",
    "\n",
    "predict(layers, X_train[0])\n",
    "train(layers, X_train, y_train, epochs, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35d4b0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.839 %\n",
      "Test  accuracy:  0.821 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy: \", calculate_accuracy_score(X_train, y_train, layers), \"%\")\n",
    "print(\"Test  accuracy: \", calculate_accuracy_score(X_test, y_test, layers), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb46c529",
   "metadata": {},
   "source": [
    "#### Looks like our model learned something!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
